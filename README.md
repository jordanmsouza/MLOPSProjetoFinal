# Projeto Final â€“ MLE / MLOps NÃ­vel 0  
AnÃ¡lise de Sentimentos em Reviews da Amazon

Este projeto implementa um pipeline de **Machine Learning + MLOps nÃ­vel 0** para anÃ¡lise de sentimentos em reviews da Amazon, desde a **ingestÃ£o dos dados** atÃ© o **serviÃ§o do modelo via API** e **monitoramento bÃ¡sico** em produÃ§Ã£o.

O objetivo Ã© responder Ã s perguntas do case proposto, mostrando um fluxo completo e reproduzÃ­vel.

---

## ğŸ§± Stack utilizada

- Python 3.9+
- pandas
- scikit-learn
- joblib
- FastAPI
- Uvicorn

---

## ğŸ“‚ Estrutura do projeto

```bash
MLOPSProjetoFinal/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ amazon_reviews_train_sample.csv
â”‚   â”‚   â””â”€â”€ amazon_reviews_test_sample.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ predictions_log.csv
â”‚   â””â”€â”€ feedback_log.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sentiment_model.joblib
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ EDA.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ serve.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“Š Fonte de dados

- Dataset: **Amazon Reviews**
- Origem: Kaggle  
- ID usado no cÃ³digo: `kritanjalijain/amazon-reviews`

O dataset jÃ¡ vem com as colunas:

- `label` â€“ rÃ³tulo numÃ©rico (1 ou 2, jÃ¡ binÃ¡rio)
- `title` â€“ tÃ­tulo curto da review
- `text` â€“ texto completo da review

Neste projeto, usei o `label` para construir a variÃ¡vel alvo de sentimento.

---

## ğŸ” Pipeline de ponta a ponta

### 1. IngestÃ£o e reduÃ§Ã£o do dataset â€“ `src/ingest_data.py`

Objetivo: baixar o dataset do Kaggle e criar uma **amostra reduzida** para facilitar o desenvolvimento local.

Principais pontos:

- Download automÃ¡tico via `kagglehub`.
- Leitura em **chunks** (`chunksize`) para nÃ£o estourar memÃ³ria.
- Amostragem do conjunto de treino e teste com limite de linhas (`target_size`).
- PadronizaÃ§Ã£o das colunas para: `["label", "title", "text"]`.

SaÃ­das:

- `data/raw/amazon_reviews_train_sample.csv`
- `data/raw/amazon_reviews_test_sample.csv`

**Comando:**

```bash
python -m src.ingest_data
```

---

### 2. PreparaÃ§Ã£o dos dados â€“ `src/data_prep.py`

Objetivo: transformar os dados crus em um formato pronto para modelagem.

Passos principais:

1. Leitura dos arquivos reduzidos (`raw`).
2. SeleÃ§Ã£o das colunas relevantes: `label` e `text`.
3. ConversÃ£o de `label` em `sentiment` binÃ¡rio:
   - `label == 2` â†’ `sentiment = 1` (positivo)
   - `label == 1` â†’ `sentiment = 0` (negativo)
4. RemoÃ§Ã£o de linhas invÃ¡lidas / nulas.
5. **RemoÃ§Ã£o da coluna `title`** por ser redundante:
   - o tÃ­tulo Ã© muito curto e costuma repetir o sentimento jÃ¡ expresso em `text`;
   - manter apenas `text` simplifica o modelo, reduz sparsidade e evita features redundantes.

SaÃ­das:

- `data/processed/train.csv` â€“ colunas: `text`, `sentiment`
- `data/processed/test.csv` â€“ colunas: `text`, `sentiment`

**Comando:**

```bash
python -m src.data_prep
```

---

### 3. AnÃ¡lise ExploratÃ³ria â€“ `notebook/EDA.ipynb`

No notebook foram feitas anÃ¡lises como:

- VisualizaÃ§Ã£o das primeiras linhas do dataset.
- DistribuiÃ§Ã£o da variÃ¡vel `label` / `sentiment`.
- Exemplos de reviews positivas e negativas.
- VerificaÃ§Ã£o de balanceamento de classes.

Principais conclusÃµes:

- O dataset Ã© binÃ¡rio (labels 1 e 2).
- HÃ¡ predominÃ¢ncia de reviews positivas.
- Os textos sÃ£o longos, favorecendo TF-IDF em n-grams.

---

### 4. Treinamento do modelo â€“ `src/train.py`

Modelo utilizado:

- Pipeline:
  - `TfidfVectorizer`
    - `max_features=40000`
    - `ngram_range=(1, 2)`
    - `stop_words="english"`
  - `LogisticRegression`
    - `max_iter=1000`
    - `n_jobs=-1`

MotivaÃ§Ã£o da escolha:

- **TF-IDF**: representaÃ§Ã£o clÃ¡ssica e eficiente para texto.
- **Logistic Regression**: simples, robusta e ideal como baseline.

MÃ©tricas calculadas:

- Accuracy  
- F1-score  
- Precision / Recall  

SaÃ­da:

- `models/sentiment_model.joblib`

**Comando:**

```bash
python -m src.train
```

---

### 5. ServiÃ§o do modelo â€“ API FastAPI (`src/serve.py`)

Endpoints:

#### `GET /health`
Verifica se o serviÃ§o estÃ¡ ativo.

#### `POST /predict`

Entrada:
```json
{
  "text": "This product is amazing!"
}
```

SaÃ­da:
```json
{
  "sentiment": 1,
  "label": "positivo",
  "confidence": 0.94
}
```

#### `POST /feedback`

Entrada:
```json
{
  "text": "This product is amazing!",
  "user_sentiment": 1
}
```

SaÃ­da:
```json
{
  "model_sentiment": 1,
  "model_label": "positivo",
  "model_confidence": 0.94,
  "user_sentiment": 1,
  "is_correct": true,
  "message": "Feedback registrado com sucesso."
}
```

**Comando para subir a API:**
```bash
uvicorn src.serve:app --reload
```

Docs automÃ¡ticas:
http://127.0.0.1:8000/docs

---

## ğŸ“ˆ Monitoramento do modelo

O monitoramento estÃ¡ dividido em trÃªs camadas:

### 1. SaÃºde do serviÃ§o (API)
- Endpoint `/health`
- Logs do servidor com status codes e tempos de resposta

### 2. Monitoramento das previsÃµes (prediction drift)
Cada chamada ao `/predict` gera um registro em:

```
logs/predictions_log.csv
```

Campos:

- timestamp  
- text_length  
- sentiment  
- confidence  

Isso permite acompanhar:
- distribuiÃ§Ã£o das previsÃµes ao longo do tempo  
- mudanÃ§as no padrÃ£o dos textos (ex.: textos muito curtos)  
- possÃ­veis sinais de drift

### 3. Qualidade do modelo em produÃ§Ã£o (feedback)

Cada chamada a `/feedback` gera:

```
logs/feedback_log.csv
```

Campos:

- timestamp  
- text_length  
- model_sentiment  
- model_confidence  
- user_sentiment  
- is_correct  

Permite calcular uma **acurÃ¡cia em produÃ§Ã£o** usando:

```
mean(is_correct)
```

E comparar com resultados offline.

---

## ğŸ§ª Como reproduzir o pipeline completo

```bash
# 1. IngestÃ£o + amostragem
python -m src.ingest_data

# 2. PreparaÃ§Ã£o dos dados
python -m src.data_prep

# 3. Treinamento do modelo
python -m src.train

# 4. Subir API
uvicorn src.serve:app --reload
```

---

## ğŸ§  DecisÃµes de modelagem (resumo)

- Uso de amostragem por chunks para processar datasets grandes.
- labels 1 e 2 transformados em sentimento (0/1).
- RemoÃ§Ã£o da coluna `title` por redundÃ¢ncia.
- TF-IDF + Logistic Regression como baseline simples e eficaz.
- ServiÃ§o via FastAPI.
- Log de previsÃµes + log de feedback para monitoramento contÃ­nuo.

---

## ğŸš€ Melhorias futuras

- Testes unitÃ¡rios e de integraÃ§Ã£o
- ContainerizaÃ§Ã£o com Docker
- Pipeline CI/CD
- Re-treino automÃ¡tico com base em feedback
- Monitoramento avanÃ§ado com EvidentlyAI

---
