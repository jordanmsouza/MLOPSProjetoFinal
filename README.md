# ğŸ§  Projeto Final â€“ MLE / MLOps NÃ­vel 0  
# **AnÃ¡lise de Sentimentos em Reviews da Amazon**

Este projeto implementa um pipeline completo de **Machine Learning + MLOps nÃ­vel 0**, passando por:

- ingestÃ£o e preparaÃ§Ã£o dos dados  
- anÃ¡lise exploratÃ³ria  
- treinamento e versionamento do modelo (MLflow)  
- serviÃ§o via API FastAPI  
- logging e monitoramento bÃ¡sico  
- execuÃ§Ã£o local e via Docker  

O objetivo foi responder ao desafio proposto, criando um fluxo **reproduzÃ­vel, escalÃ¡vel e alinhado a boas prÃ¡ticas de MLOps**.

---

## âš™ï¸ Stack utilizada

### Linguagem e bibliotecas
- Python 3.9+
- pandas  
- scikit-learn  
- joblib  

### MLOps
- MLflow (tracking + model registry)

### ServiÃ§o
- FastAPI  
- Uvicorn  

### Infraestrutura
- Docker  
- docker-compose  

---

## ğŸ“‚ Estrutura do Projeto

```bash
MLOPSProjetoFinal/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ amazon_reviews_train_sample.csv
â”‚   â”‚   â””â”€â”€ amazon_reviews_test_sample.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ predictions_log.csv
â”‚   â””â”€â”€ feedback_log.csv
â”œâ”€â”€ mlruns/                     # MLflow local (tracking + registry)
â”‚   â”œâ”€â”€ <experiments>...
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ sentiment-logreg-tfidf/
â”‚           â”œâ”€â”€ version-1/
â”‚           â””â”€â”€ meta.yaml
â”œâ”€â”€ mlruns_backup/              # Backup do registry antigo
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sentiment_model.joblib  # fallback local
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ EDA.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ serve.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“Š Fonte de Dados

Dataset pÃºblico do Kaggle:

- **Amazon Reviews**  
- ID: `kritanjalijain/amazon-reviews`

Colunas originais:

| Coluna | DescriÃ§Ã£o |
|--------|-----------|
| `label` | 1 = negativo, 2 = positivo |
| `title` | tÃ­tulo da review |
| `text` | texto completo |

Para modelagem, usamos apenas `text` e o target `sentiment` convertido para 0/1.

---

# ğŸ” Pipeline Completo

---

## **1. IngestÃ£o do Dataset â€” `src/ingest_data.py`**

O dataset completo Ã© grande (~1.5 GB), entÃ£o utilizamos:

- download automÃ¡tico via `kagglehub`
- leitura em chunks para evitar estouro de memÃ³ria
- amostragem controlada para desenvolvimento mais rÃ¡pido

SaÃ­das:

```
data/raw/amazon_reviews_train_sample.csv
data/raw/amazon_reviews_test_sample.csv
```

**Executar:**

```bash
python -m src.ingest_data
```

---

## **2. PreparaÃ§Ã£o dos Dados â€” `src/data_prep.py`**

Processos aplicados:

- uso das colunas `label` e `text`
- mapeamento de `label â†’ sentiment`  
  - 1 â†’ 0 (negativo)  
  - 2 â†’ 1 (positivo)
- remoÃ§Ã£o da coluna `title` (redundante)
- limpeza de linhas inconsistentes

SaÃ­das:

```
data/processed/train.csv
data/processed/test.csv
```

**Executar:**

```bash
python -m src.data_prep
```

---

## **3. EDA â€” `notebook/EDA.ipynb`**

AnÃ¡lises realizadas:

- distribuiÃ§Ã£o das classes  
- comprimento dos textos  
- amostras de textos positivos e negativos  
- contagem de tokens por classe  
- estimativa de memÃ³ria para o dataset completo  
- justificativa da reduÃ§Ã£o do dataset  

ConclusÃµes:

- O dataset reduzido mantÃ©m representatividade  
- TF-IDF Ã© apropriado  
- Logistic Regression funciona muito bem como baseline  

---

## **4. Treinamento + Registro do Modelo â€” `src/train.py`**

Modelo utilizado:

### **TF-IDF**
- `max_features=40000`
- `ngram_range=(1, 2)`
- `stop_words="english"`

### **Logistic Regression**
- `max_iter=1000`
- `n_jobs=-1`

MÃ©tricas:

- Accuracy  
- Precision  
- Recall  
- F1-score  

### Registro no MLflow

```python
mlflow.register_model(
    model_uri=f"runs:/{run_id}/model",
    name="sentiment-logreg-tfidf"
)
```

SaÃ­da local (fallback):

```
models/sentiment_model.joblib
```

**Executar:**

```bash
python -m src.train
```

---

## **5. Servindo o Modelo â€” `src/serve.py`**

A API tenta carregar:

1. Modelo do **MLflow Registry** (alias `latest`)  
2. Se falhar â†’ fallback para `sentiment_model.joblib`

### **Endpoints**

#### `GET /health`
Checa se o serviÃ§o estÃ¡ no ar.

#### `POST /predict`
Entrada:
```json
{"text": "This product is amazing!"}
```

Resposta:
```json
{
  "sentiment": 1,
  "label": "positivo",
  "confidence": 0.94
}
```

#### `POST /feedback`
Armazena feedback do usuÃ¡rio:

```
logs/feedback_log.csv
logs/predictions_log.csv
```

**Executar API localmente:**

```bash
uvicorn src.serve:app --reload
```

Swagger:
```
http://localhost:8000/docs
```

---

# ğŸ³ ExecuÃ§Ã£o com Docker

### Subir API + MLflow UI

```bash
docker compose up --build
```

### Acessos

- API â†’ http://localhost:8000  
- Swagger â†’ http://localhost:8000/docs  
- MLflow UI â†’ http://localhost:5000  

---

# ğŸ“ˆ Monitoramento

### Prediction Log â†’ drift bÃ¡sico

Arquivo:
```
logs/predictions_log.csv
```

Campos:
- timestamp  
- text_length  
- model_sentiment  
- confidence  

### Feedback Loop â†’ qualidade real em produÃ§Ã£o

Arquivo:
```
logs/feedback_log.csv
```

Campos:
- user_sentiment  
- model_sentiment  
- is_correct  

Permite medir:

- acurÃ¡cia de produÃ§Ã£o  
- divergÃªncia entre offline x online  

---

# ğŸ§  DecisÃµes de Modelagem

- chunking para otimizar ingestÃ£o  
- remoÃ§Ã£o de `title` por redundÃ¢ncia  
- TF-IDF + Logistic Regression = baseline robusto  
- MLflow como registry + tracking  
- logs estruturados para monitoramento  
- API FastAPI para servir o modelo  

---

# ğŸš€ Melhorias Futuras

- Testes unitÃ¡rios e integraÃ§Ã£o  
- EvidentlyAI para monitoramento avanÃ§ado de drift  
- CI/CD com pipelines automÃ¡ticos  
- Retreino automÃ¡tico baseado em feedback do usuÃ¡rio  
- OrquestraÃ§Ã£o com Airflow ou Prefect  

---
